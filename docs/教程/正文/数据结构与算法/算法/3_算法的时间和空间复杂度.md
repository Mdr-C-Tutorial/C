# 时间复杂度

## 1. 含义

1. 算法在特定输入下的**运行时间**：指执行的基本操作数或步数
2. **时间复杂度**是定性描述该算法运行时间的函数，可以用来估计该算法的运行时间
3. 当输入规模足够大的时候，这个函数的低阶项和最高阶项的常数项对函数值的影响相较于最高阶项指数对函数值的影响来说可以忽略不计，也就是说只对运行时间的**次数**做描述

## 2. 渐进记号

渐进记号描述函数的增长趋势。五个渐进记号如下：

### 2.1. 定义

1. $\Theta(g(n))=\{f(n)\space |\space\exists\space c_1,\space c_2,\space n_0>0,\forall\space n \ge n_0,\space 0\le c_1g(n)\le f(n)\le c_2g(n)\}$
2. $O(g(n))=\{f(n)\space |\space\exists\space c,\space n_0>0,\forall\space n \ge n_0,\space 0\le f(n)\le cg(n)\}$
3. $\Omega(g(n))=\{f(n)\space |\space\exists\space c,\space n_0>0,\forall\space n \ge n_0,\space 0\le cg(n)\le f(n)\}$
4. $o(g(n))=\{f(n)\space |\space\forall\space c\gt 0,\space\exists\space n_0\gt 0,\space\forall n\ge n_0,\space 0\le f(n)\lt cg(n)\}$
5. $\omega(g(n))=\{f(n)\space |\space\forall\space c\gt 0,\space\exists\space n_0\gt 0,\space\forall n\ge n_0,\space 0\le cg(n)\lt f(n)\}$

::: tip 等号代替属于

为了方便，当 $f(n)\in O(g(n))$ 时，记作 $f(n)=O(g(n))$。

:::

其中，第 2.4.5. 可以更快速地用极限定义：

1. $$f(n) \in O(g(n)) \Leftrightarrow \lim_{n \to \infin} \frac{f(n)}{g(n)}=C$$
2. $$f(n) \in o(g(n)) \Leftrightarrow \lim_{n \to \infin} \frac{f(n)}{g(n)}=0$$
3. $$f(n) \in \omega(g(n)) \Leftrightarrow \lim_{n \to \infin} \frac{f(n)}{g(n)}=\infin$$

### 2.2. 性质

#### 2.2.1. 传递性

1. $f(n)=\Theta(g(n))\wedge g(n)=\Theta(h(n))\Rightarrow f(n)=\Theta(h(n))$
2. $f(n)=O(g(n))\wedge g(n)=O(h(n))\Rightarrow f(n)=O(h(n))$
3. $f(n)=\Omega(g(n))\wedge g(n)=\Omega(h(n))\Rightarrow f(n)=\Omega(h(n))$
4. $f(n)=o(g(n))\wedge g(n)=o(h(n))\Rightarrow f(n)=o(h(n))$
5. $f(n)=\omega(g(n))\wedge g(n)=\omega(h(n))\Rightarrow f(n)=\omega(h(n))$

#### 2.2.2. 自反性

1. $f(n)=\Theta(f(n))$
2. $f(n)=O(f(n))$
3. $f(n)=\Omega(f(n))$

### 2.2.3. 对称性和转置对称性

1. $f(n)=\Theta(g(n))\Leftrightarrow g(n)=\Theta(f(n))$
2. $f(n)=O(g(n))\Leftrightarrow g(n)=\Omega(f(n))$
3. $f(n)=o(g(n))\Leftrightarrow g(n)=\omega(f(n))$

## 2.3 时间复杂度的表示

1. 时间复杂度可以用渐进记号表示，最常用的是大 O 记号。
2. 大多数情况下，我们只关注算法的**最坏情况运行时间**：
   1. 对大部分算法来说，最坏情况经常出现；
   2. **平均情况运行时间**很可能等于最坏情况运行时间；
   3. 有例外，比如**快速排序**。

## 2.4 例子

1. 常数函数的时间复杂度是 $\Theta(1)$，也可写成 $\Theta(n^0)$（为什么？）
2. 函数的增长不一定能比较：
   $f(n)=n$，$g(n)=n^{1+\sin n}$
   此时 $f(n)=O(g(n))$ 和 $f(n)=\Omega(g(n))$ 均不成立（为什么？）
3. $\lg(n!)=\Theta(n\lg n)$
   - 由 [**斯特林公式**](https://zhuanlan.zhihu.com/p/145007068)，$\lg(n!) \approx \lg(\sqrt{2\pi n} (\frac{n}{e})^n)=\lg(\sqrt{2\pi n}) + n\lg(n) – n\lg(e)$。又因为 $\lg(\sqrt{2\pi n})$ 和 $- n\lg(e)$ 均可视为较 $n\lg(n)$ 小的项，所以 $\lg(n!) = O(n\lg{n})$。
   - 又因为 $n! \geq \left(\frac{n}{2}\right)^{\frac{n}{2}}$（为什么？）  
     两边取对数，得 $\lg(n!) \geq \frac{n}{2} \lg(\frac{n}{2})$  
     $\implies\lg(n!) \geq c \cdot n\lg{n}$ （其中$c$是某个常数）  
     $\implies\lg{n}! = \Omega(n\lg{n})$
   - 由以上两式子可得，$\lg{n}! = \Theta(n\lg{n})$

::: info $\ln$ 的底数呢？

经常有人疑惑 $\Theta(n)=\lg n$ 中 lg 的底数是多少；  
对数的底数是几无关紧要，因为：根据换底公式，不同底数的对数之间只差一个常数，而计算时间复杂度的时候不考虑常数。

:::

## 3. 空间复杂度

### 1. 定义

算法的**空间复杂度**指该算法**执行过程中**所需要消耗的存储空间资源

::: warning “执行过程中”

**不要**把输入数据所占的存储空间包括在内。

:::

### 2. 表示方法

与时间复杂度表示方法相同
